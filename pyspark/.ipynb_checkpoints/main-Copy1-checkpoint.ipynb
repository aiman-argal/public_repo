{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pyspark in /usr/local/lib/python3.9/site-packages (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.9/site-packages (from pyspark) (0.10.9.7)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/aiman_argal/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.9/site-packages (from pandas) (2020.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.9/site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import mean,min,max,sum, avg\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aiman</td>\n",
       "      <td>31</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Said</td>\n",
       "      <td>25</td>\n",
       "      <td>Rabat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Momo</td>\n",
       "      <td>12</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name   Age  Location\n",
       "0  Aiman    31     Paris\n",
       "1   Said    25     Rabat\n",
       "2   Momo    12    Dallas"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('pyspark session').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('data.csv',header=True ,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---------+\n",
      "| Name| Age| Location|\n",
      "+-----+----+---------+\n",
      "|Aiman|31.0|    Paris|\n",
      "| Said|25.0|    Rabat|\n",
      "| Momo|12.0|   Dallas|\n",
      "+-----+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('Name', StringType(), True), StructField(' Age', DoubleType(), True), StructField(' Location', StringType(), True)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |--  Age: double (nullable = true)\n",
      " |--  Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[Name: string,  Age: double,  Location: string]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "| Name| Location|\n",
      "+-----+---------+\n",
      "|Aiman|    Paris|\n",
      "| Said|    Rabat|\n",
      "| Momo|   Dallas|\n",
      "+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['Name',' Location']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), (' Age', 'double'), (' Location', 'string')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------------------+---------+\n",
      "|summary| Name|               Age| Location|\n",
      "+-------+-----+------------------+---------+\n",
      "|  count|    3|                 3|        3|\n",
      "|   mean| NULL|22.666666666666668|     NULL|\n",
      "| stddev| NULL|  9.71253485622231|     NULL|\n",
      "|    min|Aiman|              12.0|   Dallas|\n",
      "|    max| Said|              31.0|    Rabat|\n",
      "+-------+-----+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark_changed = df_pyspark.withColumn('Age two years ago',df_pyspark[' Age']-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---------+\n",
      "| Name| Age| Location|\n",
      "+-----+----+---------+\n",
      "|Aiman|31.0|    Paris|\n",
      "| Said|25.0|    Rabat|\n",
      "| Momo|12.0|   Dallas|\n",
      "+-----+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---------+-----------------+\n",
      "| Name| Age| Location|Age two years ago|\n",
      "+-----+----+---------+-----------------+\n",
      "|Aiman|31.0|    Paris|             29.0|\n",
      "| Said|25.0|    Rabat|             23.0|\n",
      "| Momo|12.0|   Dallas|             10.0|\n",
      "+-----+----+---------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark_changed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_equal = df_pyspark_changed.drop('Age two years ago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark == df_pyspark_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string,  Age: double,   Location: string]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.withColumnRenamed(' Location','  Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: double,  Location: string]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.withColumnsRenamed({'  Location':'Location',' Age':'Age'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = spark.read.csv('data copy.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------+\n",
      "| Name| Age|   Location|\n",
      "+-----+----+-----------+\n",
      "|Aiman|  31|      Paris|\n",
      "| Said|  25|      Rabat|\n",
      "|Aiman|  12|     Dallas|\n",
      "| Said|  28|    Nowhere|\n",
      "|Aiman|  24|    Kenitra|\n",
      "|David|  28|       Lyon|\n",
      "|David|  35| Casablanca|\n",
      "+-----+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |--  Age: integer (nullable = true)\n",
      " |--  Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------+\n",
      "| Name| Age|   Location|\n",
      "+-----+----+-----------+\n",
      "|Aiman|  31|      Paris|\n",
      "| Said|  25|      Rabat|\n",
      "|Aiman|  12|     Dallas|\n",
      "| Said|  28|    Nowhere|\n",
      "|Aiman|  24|    Kenitra|\n",
      "|David|  28|       Lyon|\n",
      "|David|  35| Casablanca|\n",
      "+-----+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------+\n",
      "| Name| Age|   Location|\n",
      "+-----+----+-----------+\n",
      "|Aiman|  31|      Paris|\n",
      "| Said|  25|      Rabat|\n",
      "|Aiman|  12|     Dallas|\n",
      "| Said|  28|    Nowhere|\n",
      "|Aiman|  24|    Kenitra|\n",
      "|David|  28|       Lyon|\n",
      "|David|  35| Casablanca|\n",
      "+-----+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------+\n",
      "| Name| Age|   Location|\n",
      "+-----+----+-----------+\n",
      "|Aiman|  31|      Paris|\n",
      "| Said|  25|      Rabat|\n",
      "|Aiman|  12|     Dallas|\n",
      "| Said|  28|    Nowhere|\n",
      "|Aiman|  24|    Kenitra|\n",
      "|David|  28|       Lyon|\n",
      "|David|  35| Casablanca|\n",
      "+-----+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.na.drop(how= 'any',subset='Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------+\n",
      "| Name| Age|   Location|\n",
      "+-----+----+-----------+\n",
      "|Aiman|  31|      Paris|\n",
      "| Said|  25|      Rabat|\n",
      "|Aiman|  12|     Dallas|\n",
      "| Said|  28|    Nowhere|\n",
      "|Aiman|  24|    Kenitra|\n",
      "|David|  28|       Lyon|\n",
      "|David|  35| Casablanca|\n",
      "+-----+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.na.fill('No Value bro').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(inputCol=' Age', outputCol= 'Age Imputed').setStrategy('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------+-----------+\n",
      "| Name| Age|   Location|Age Imputed|\n",
      "+-----+----+-----------+-----------+\n",
      "|Aiman|  31|      Paris|         31|\n",
      "| Said|  25|      Rabat|         25|\n",
      "|Aiman|  12|     Dallas|         12|\n",
      "| Said|  28|    Nowhere|         28|\n",
      "|Aiman|  24|    Kenitra|         24|\n",
      "|David|  28|       Lyon|         28|\n",
      "|David|  35| Casablanca|         35|\n",
      "+-----+----+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_missing).transform(df_missing).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------+\n",
      "| Name| Age|   Location|\n",
      "+-----+----+-----------+\n",
      "|Aiman|  31|      Paris|\n",
      "| Said|  25|      Rabat|\n",
      "|Aiman|  12|     Dallas|\n",
      "| Said|  28|    Nowhere|\n",
      "|Aiman|  24|    Kenitra|\n",
      "|David|  28|       Lyon|\n",
      "|David|  35| Casablanca|\n",
      "+-----+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = imputer.fit(df_missing).transform(df_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------+-----------+\n",
      "| Name| Age|   Location|Age Imputed|\n",
      "+-----+----+-----------+-----------+\n",
      "|Aiman|  31|      Paris|         31|\n",
      "| Said|  25|      Rabat|         25|\n",
      "|Aiman|  12|     Dallas|         12|\n",
      "| Said|  28|    Nowhere|         28|\n",
      "|Aiman|  24|    Kenitra|         24|\n",
      "|David|  28|       Lyon|         28|\n",
      "|David|  35| Casablanca|         35|\n",
      "+-----+----+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------+-----------+\n",
      "| Name| Age|   Location|Age Imputed|\n",
      "+-----+----+-----------+-----------+\n",
      "|Aiman|  31|      Paris|         31|\n",
      "| Said|  25|      Rabat|         25|\n",
      "| Said|  28|    Nowhere|         28|\n",
      "|Aiman|  24|    Kenitra|         24|\n",
      "|David|  28|       Lyon|         28|\n",
      "|David|  35| Casablanca|         35|\n",
      "+-----+----+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.filter('`Age Imputed` > 20.0').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------+\n",
      "| Name|Age|   Location|\n",
      "+-----+---+-----------+\n",
      "|Aiman| 31|      Paris|\n",
      "| Said| 25|      Rabat|\n",
      "|Aiman| 12|     Dallas|\n",
      "| Said| 28|    Nowhere|\n",
      "|Aiman| 24|    Kenitra|\n",
      "|David| 28|       Lyon|\n",
      "|David| 35| Casablanca|\n",
      "+-----+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.drop('Age Imputed').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------+-----------+\n",
      "| Name|Age|   Location|Age Imputed|\n",
      "+-----+---+-----------+-----------+\n",
      "|Aiman| 31|      Paris|         31|\n",
      "| Said| 28|    Nowhere|         28|\n",
      "|David| 28|       Lyon|         28|\n",
      "|David| 35| Casablanca|         35|\n",
      "+-----+---+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df_missing.filter(col('Age Imputed')> 26).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------+-----------+\n",
      "| Name|Age|   Location|Age Imputed|\n",
      "+-----+---+-----------+-----------+\n",
      "|Aiman| 31|      Paris|         31|\n",
      "|David| 35| Casablanca|         35|\n",
      "+-----+---+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.filter(df_missing['Age']> 30).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField('Name', StringType(), True), \n",
    "                     StructField('Age', IntegerType(), True), \n",
    "                     StructField('Location',StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = spark.read.csv('data copy.csv', header=True, schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------+\n",
      "| Name|Age|   Location|\n",
      "+-----+---+-----------+\n",
      "|Aiman| 31|      Paris|\n",
      "| Said| 25|      Rabat|\n",
      "|Aiman| 12|     Dallas|\n",
      "| Said| 28|    Nowhere|\n",
      "|Aiman| 24|    Kenitra|\n",
      "|David| 28|       Lyon|\n",
      "|David| 35| Casablanca|\n",
      "+-----+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputerAge = Imputer(inputCol='Age', outputCol= 'Age Imputed').setStrategy('median')\n",
    "df_missing = imputerAge.fit(df_missing).transform(df_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------+-----------+\n",
      "| Name|Age|   Location|Age Imputed|\n",
      "+-----+---+-----------+-----------+\n",
      "|Aiman| 31|      Paris|         31|\n",
      "| Said| 25|      Rabat|         25|\n",
      "|Aiman| 12|     Dallas|         12|\n",
      "| Said| 28|    Nowhere|         28|\n",
      "|Aiman| 24|    Kenitra|         24|\n",
      "|David| 28|       Lyon|         28|\n",
      "|David| 35| Casablanca|         35|\n",
      "+-----+---+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+--------+-----------+\n",
      "|Name|Age|Location|Age Imputed|\n",
      "+----+---+--------+-----------+\n",
      "|Said| 25|   Rabat|         25|\n",
      "+----+---+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.filter(col('Age Imputed') == 25).filter(col('Location') == ' Rabat').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| Name|Age|\n",
      "+-----+---+\n",
      "|Aiman| 31|\n",
      "| Said| 28|\n",
      "|David| 28|\n",
      "|David| 35|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.filter((df_missing['Age Imputed'] > 25) | (df_missing['Location'] == ' Paris')).select(['Name','Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_missing.filter(col('Age Imputed') == 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df_missing.na.fill('CasaBlanca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------+-----------+\n",
      "| Name|Age|   Location|Age Imputed|\n",
      "+-----+---+-----------+-----------+\n",
      "|Aiman| 31|      Paris|         31|\n",
      "| Said| 25|      Rabat|         25|\n",
      "|Aiman| 12|     Dallas|         12|\n",
      "| Said| 28|    Nowhere|         28|\n",
      "|Aiman| 24|    Kenitra|         24|\n",
      "|David| 28|       Lyon|         28|\n",
      "|David| 35| Casablanca|         35|\n",
      "+-----+---+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-----------+\n",
      "| Name|   Location|Age Imputed|\n",
      "+-----+-----------+-----------+\n",
      "|Aiman|      Paris|         31|\n",
      "| Said|      Rabat|         25|\n",
      "|Aiman|     Dallas|         12|\n",
      "| Said|    Nowhere|         28|\n",
      "|Aiman|    Kenitra|         24|\n",
      "|David|       Lyon|         28|\n",
      "|David| Casablanca|         35|\n",
      "+-----+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.drop('Age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_now = spark.read.csv('data copy.csv',header=True, schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------+\n",
      "| Name|Age|   Location|\n",
      "+-----+---+-----------+\n",
      "|Aiman| 31|      Paris|\n",
      "| Said| 25|      Rabat|\n",
      "|Aiman| 12|     Dallas|\n",
      "| Said| 28|    Nowhere|\n",
      "|Aiman| 24|    Kenitra|\n",
      "|David| 28|       Lyon|\n",
      "|David| 35| Casablanca|\n",
      "+-----+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_now.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_now = spark.read.csv('data copy.csv',header=True, schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------+\n",
      "| Name|Age|   Location|\n",
      "+-----+---+-----------+\n",
      "|Aiman| 31|      Paris|\n",
      "| Said| 25|      Rabat|\n",
      "|Aiman| 12|     Dallas|\n",
      "| Said| 28|    Nowhere|\n",
      "|Aiman| 24|    Kenitra|\n",
      "|David| 28|       Lyon|\n",
      "|David| 35| Casablanca|\n",
      "+-----+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_now.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_now.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "| name|sum(Age)|\n",
      "+-----+--------+\n",
      "|Aiman|      67|\n",
      "| Said|      53|\n",
      "|David|      63|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_now.groupBy('name').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|   Location|avg(Age)|\n",
      "+-----------+--------+\n",
      "|    Nowhere|    28.0|\n",
      "|       Lyon|    28.0|\n",
      "|    Kenitra|    24.0|\n",
      "|     Dallas|    12.0|\n",
      "|      Paris|    31.0|\n",
      "|      Rabat|    25.0|\n",
      "| Casablanca|    35.0|\n",
      "+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_now.groupBy('Location').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|   Location|count|\n",
      "+-----------+-----+\n",
      "|    Nowhere|    1|\n",
      "|       Lyon|    1|\n",
      "|    Kenitra|    1|\n",
      "|     Dallas|    1|\n",
      "|      Paris|    1|\n",
      "|      Rabat|    1|\n",
      "| Casablanca|    1|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_now.groupBy('Location').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------------+\n",
      "| name|max(age)|min(Location)|\n",
      "+-----+--------+-------------+\n",
      "|Aiman|      31|       Dallas|\n",
      "|David|      35|   Casablanca|\n",
      "| Said|      28|        Rabat|\n",
      "+-----+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_now.groupBy('name').agg({'age':'max', 'Location':'min'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------+\n",
      "| Name|Age|   Location|\n",
      "+-----+---+-----------+\n",
      "|Aiman| 31|      Paris|\n",
      "| Said| 25|      Rabat|\n",
      "|Aiman| 12|     Dallas|\n",
      "| Said| 28|    Nowhere|\n",
      "|Aiman| 24|    Kenitra|\n",
      "|David| 28|       Lyon|\n",
      "|David| 35| Casablanca|\n",
      "+-----+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_now.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_now.createOrReplaceTempView('Table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+--------+\n",
      "|Name|Age|Location|\n",
      "+----+---+--------+\n",
      "|Said| 25|   Rabat|\n",
      "+----+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM Table WHERE Age = '25'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| Name|\n",
      "+-----+\n",
      "|Aiman|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Name FROM Table WHERE Location = ' Paris'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_now_copy = df_now.replace('David', 'Simon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------+\n",
      "| Name|Age|   Location|\n",
      "+-----+---+-----------+\n",
      "|Aiman| 31|      Paris|\n",
      "| Said| 25|      Rabat|\n",
      "|Aiman| 12|     Dallas|\n",
      "| Said| 28|    Nowhere|\n",
      "|Aiman| 24|    Kenitra|\n",
      "|Simon| 28|       Lyon|\n",
      "|Simon| 35| Casablanca|\n",
      "+-----+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_now_copy.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unified = df_now.union(df_now_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unified.createOrReplaceTempView('BigTable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|col_name|\n",
      "+--------+\n",
      "|    Name|\n",
      "|     Age|\n",
      "|Location|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW columns FROM BigTable\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| Name|\n",
      "+-----+\n",
      "| Said|\n",
      "|David|\n",
      "| Said|\n",
      "|Simon|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Name from BigTable WHERE Age = 28\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------+\n",
      "| Name|Age|   Location|\n",
      "+-----+---+-----------+\n",
      "|Aiman| 31|      Paris|\n",
      "| Said| 25|      Rabat|\n",
      "|Aiman| 12|     Dallas|\n",
      "| Said| 28|    Nowhere|\n",
      "|Aiman| 24|    Kenitra|\n",
      "|David| 28|       Lyon|\n",
      "|David| 35| Casablanca|\n",
      "|Aiman| 31|      Paris|\n",
      "| Said| 25|      Rabat|\n",
      "|Aiman| 12|     Dallas|\n",
      "| Said| 28|    Nowhere|\n",
      "|Aiman| 24|    Kenitra|\n",
      "|Simon| 28|       Lyon|\n",
      "|Simon| 35| Casablanca|\n",
      "+-----+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM BigTable\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'Age', 'Location']\n"
     ]
    }
   ],
   "source": [
    "print(df_unified.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = spark.read.csv('tested.csv', header = True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|        892|       0|     3|    Kelly, Mr. James|  male|34.5|    0|    0|          330911| 7.8292| NULL|       Q|\n",
      "|        893|       1|     3|Wilkes, Mrs. Jame...|female|47.0|    1|    0|          363272|    7.0| NULL|       S|\n",
      "|        894|       0|     2|Myles, Mr. Thomas...|  male|62.0|    0|    0|          240276| 9.6875| NULL|       Q|\n",
      "|        895|       0|     3|    Wirz, Mr. Albert|  male|27.0|    0|    0|          315154| 8.6625| NULL|       S|\n",
      "|        896|       1|     3|Hirvonen, Mrs. Al...|female|22.0|    1|    1|         3101298|12.2875| NULL|       S|\n",
      "|        897|       0|     3|Svensson, Mr. Joh...|  male|14.0|    0|    0|            7538|  9.225| NULL|       S|\n",
      "|        898|       1|     3|Connolly, Miss. Kate|female|30.0|    0|    0|          330972| 7.6292| NULL|       Q|\n",
      "|        899|       0|     2|Caldwell, Mr. Alb...|  male|26.0|    1|    1|          248738|   29.0| NULL|       S|\n",
      "|        900|       1|     3|Abrahim, Mrs. Jos...|female|18.0|    0|    0|            2657| 7.2292| NULL|       C|\n",
      "|        901|       0|     3|Davies, Mr. John ...|  male|21.0|    2|    0|       A/4 48871|  24.15| NULL|       S|\n",
      "|        902|       0|     3|    Ilieff, Mr. Ylio|  male|NULL|    0|    0|          349220| 7.8958| NULL|       S|\n",
      "|        903|       0|     1|Jones, Mr. Charle...|  male|46.0|    0|    0|             694|   26.0| NULL|       S|\n",
      "|        904|       1|     1|Snyder, Mrs. John...|female|23.0|    1|    0|           21228|82.2667|  B45|       S|\n",
      "|        905|       0|     2|Howard, Mr. Benjamin|  male|63.0|    1|    0|           24065|   26.0| NULL|       S|\n",
      "|        906|       1|     1|Chaffee, Mrs. Her...|female|47.0|    1|    0|     W.E.P. 5734| 61.175|  E31|       S|\n",
      "|        907|       1|     2|del Carlo, Mrs. S...|female|24.0|    1|    0|   SC/PARIS 2167|27.7208| NULL|       C|\n",
      "|        908|       0|     2|   Keane, Mr. Daniel|  male|35.0|    0|    0|          233734|  12.35| NULL|       Q|\n",
      "|        909|       0|     3|   Assaf, Mr. Gerios|  male|21.0|    0|    0|            2692|  7.225| NULL|       C|\n",
      "|        910|       1|     3|Ilmakangas, Miss....|female|27.0|    1|    0|STON/O2. 3101270|  7.925| NULL|       S|\n",
      "|        911|       1|     3|\"Assaf Khalil, Mr...|female|45.0|    0|    0|            2696|  7.225| NULL|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType([StructField('PassengerId', IntegerType(), True), StructField('Survived', IntegerType(), True), StructField('Pclass', IntegerType(), True), StructField('Name', StringType(), True), StructField('Sex', StringType(), True), StructField('Age', DoubleType(), True), StructField('SibSp', IntegerType(), True), StructField('Parch', IntegerType(), True), StructField('Ticket', StringType(), True), StructField('Fare', DoubleType(), True), StructField('Cabin', StringType(), True), StructField('Embarked', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "print(dataf.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+-----+--------+\n",
      "|summary|       PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|             Parch|            Ticket|              Fare|Cabin|Embarked|\n",
      "+-------+------------------+-------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+-----+--------+\n",
      "|  count|               418|                418|               418|                 418|   418|               332|               418|               418|               418|               417|   91|     418|\n",
      "|   mean|            1100.5|0.36363636363636365|2.2655502392344498|                NULL|  NULL|30.272590361445783|0.4473684210526316|0.3923444976076555|223850.98986486485|  35.6271884892086| NULL|    NULL|\n",
      "| stddev|120.81045760473994| 0.4816221409322309|0.8418375519640503|                NULL|  NULL|14.181209235624424|0.8967595611217135|0.9814288785371694| 369523.7764694362|55.907576179973844| NULL|    NULL|\n",
      "|    min|               892|                  0|                 1|\"Assaf Khalil, Mr...|female|              0.17|                 0|                 0|            110469|               0.0|  A11|       C|\n",
      "|    max|              1309|                  1|                 3|van Billiard, Mas...|  male|              76.0|                 8|                 9|       W.E.P. 5734|          512.3292|   G6|       S|\n",
      "+-------+------------------+-------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataf.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+\n",
      "|summary|           Survived|            Pclass|\n",
      "+-------+-------------------+------------------+\n",
      "|  count|                418|               418|\n",
      "|   mean|0.36363636363636365|2.2655502392344498|\n",
      "| stddev| 0.4816221409322309|0.8418375519640503|\n",
      "|    min|                  0|                 1|\n",
      "|    max|                  1|                 3|\n",
      "+-------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataf.describe(['Survived', 'Pclass']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf_drop = dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+-------+---------------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|     Ticket|   Fare|          Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+-------+---------------+--------+\n",
      "|        904|       1|     1|Snyder, Mrs. John...|female|23.0|    1|    0|      21228|82.2667|            B45|       S|\n",
      "|        906|       1|     1|Chaffee, Mrs. Her...|female|47.0|    1|    0|W.E.P. 5734| 61.175|            E31|       S|\n",
      "|        916|       1|     1|Ryerson, Mrs. Art...|female|48.0|    1|    3|   PC 17608|262.375|B57 B59 B63 B66|       C|\n",
      "|        918|       1|     1|Ostby, Miss. Hele...|female|22.0|    0|    1|     113509|61.9792|            B36|       C|\n",
      "|        920|       0|     1|Brady, Mr. John B...|  male|41.0|    0|    0|     113054|   30.5|            A21|       S|\n",
      "|        926|       0|     1|Mock, Mr. Philipp...|  male|30.0|    1|    0|      13236|  57.75|            C78|       C|\n",
      "|        936|       1|     1|Kimball, Mrs. Edw...|female|45.0|    1|    0|      11753|52.5542|            D19|       S|\n",
      "|        938|       0|     1|Chevre, Mr. Paul ...|  male|45.0|    0|    0|   PC 17594|   29.7|             A9|       C|\n",
      "|        940|       1|     1|Bucknell, Mrs. Wi...|female|60.0|    0|    0|      11813|76.2917|            D15|       C|\n",
      "|        942|       0|     1|Smith, Mr. Lucien...|  male|24.0|    1|    0|      13695|   60.0|            C31|       S|\n",
      "|        945|       1|     1|Fortune, Miss. Et...|female|28.0|    3|    2|      19950|  263.0|    C23 C25 C27|       S|\n",
      "|        949|       0|     3|Abelseth, Mr. Ola...|  male|25.0|    0|    0|     348122|   7.65|          F G63|       S|\n",
      "|        951|       1|     1|Chaudanson, Miss....|female|36.0|    0|    0|   PC 17608|262.375|            B61|       C|\n",
      "|        956|       0|     1|Ryerson, Master. ...|  male|13.0|    2|    2|   PC 17608|262.375|B57 B59 B63 B66|       C|\n",
      "|        960|       0|     1|Tucker, Mr. Gilbe...|  male|31.0|    0|    0|       2543|28.5375|            C53|       C|\n",
      "|        961|       1|     1|Fortune, Mrs. Mar...|female|60.0|    1|    4|      19950|  263.0|    C23 C25 C27|       S|\n",
      "|        965|       0|     1|Ovies y Rodriguez...|  male|28.5|    0|    0|   PC 17562|27.7208|            D43|       C|\n",
      "|        966|       1|     1|Geiger, Miss. Amalie|female|35.0|    0|    0|     113503|  211.5|           C130|       C|\n",
      "|        967|       0|     1|  Keeping, Mr. Edwin|  male|32.5|    0|    0|     113503|  211.5|           C132|       C|\n",
      "|        969|       1|     1|Cornell, Mrs. Rob...|female|55.0|    2|    0|      11770|   25.7|           C101|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+-------+---------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataf_drop.na.drop('any' ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf[dataf['Survived'] == 0].count() + dataf[dataf['Survived']==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = dataf.groupBy(['Survived']).agg({'age':'min','fare':'sum'}).withColumnRenamed('min(age)','age_min').withColumnRenamed('sum(fare)','sum_fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = df_age.withColumn('max_age', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|        892|       0|     3|    Kelly, Mr. James|  male|34.5|    0|    0|          330911| 7.8292| NULL|       Q|\n",
      "|        893|       1|     3|Wilkes, Mrs. Jame...|female|47.0|    1|    0|          363272|    7.0| NULL|       S|\n",
      "|        894|       0|     2|Myles, Mr. Thomas...|  male|62.0|    0|    0|          240276| 9.6875| NULL|       Q|\n",
      "|        895|       0|     3|    Wirz, Mr. Albert|  male|27.0|    0|    0|          315154| 8.6625| NULL|       S|\n",
      "|        896|       1|     3|Hirvonen, Mrs. Al...|female|22.0|    1|    1|         3101298|12.2875| NULL|       S|\n",
      "|        897|       0|     3|Svensson, Mr. Joh...|  male|14.0|    0|    0|            7538|  9.225| NULL|       S|\n",
      "|        898|       1|     3|Connolly, Miss. Kate|female|30.0|    0|    0|          330972| 7.6292| NULL|       Q|\n",
      "|        899|       0|     2|Caldwell, Mr. Alb...|  male|26.0|    1|    1|          248738|   29.0| NULL|       S|\n",
      "|        900|       1|     3|Abrahim, Mrs. Jos...|female|18.0|    0|    0|            2657| 7.2292| NULL|       C|\n",
      "|        901|       0|     3|Davies, Mr. John ...|  male|21.0|    2|    0|       A/4 48871|  24.15| NULL|       S|\n",
      "|        902|       0|     3|    Ilieff, Mr. Ylio|  male|NULL|    0|    0|          349220| 7.8958| NULL|       S|\n",
      "|        903|       0|     1|Jones, Mr. Charle...|  male|46.0|    0|    0|             694|   26.0| NULL|       S|\n",
      "|        904|       1|     1|Snyder, Mrs. John...|female|23.0|    1|    0|           21228|82.2667|  B45|       S|\n",
      "|        905|       0|     2|Howard, Mr. Benjamin|  male|63.0|    1|    0|           24065|   26.0| NULL|       S|\n",
      "|        906|       1|     1|Chaffee, Mrs. Her...|female|47.0|    1|    0|     W.E.P. 5734| 61.175|  E31|       S|\n",
      "|        907|       1|     2|del Carlo, Mrs. S...|female|24.0|    1|    0|   SC/PARIS 2167|27.7208| NULL|       C|\n",
      "|        908|       0|     2|   Keane, Mr. Daniel|  male|35.0|    0|    0|          233734|  12.35| NULL|       Q|\n",
      "|        909|       0|     3|   Assaf, Mr. Gerios|  male|21.0|    0|    0|            2692|  7.225| NULL|       C|\n",
      "|        910|       1|     3|Ilmakangas, Miss....|female|27.0|    1|    0|STON/O2. 3101270|  7.925| NULL|       S|\n",
      "|        911|       1|     3|\"Assaf Khalil, Mr...|female|45.0|    0|    0|            2696|  7.225| NULL|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|        892|       0|     3|    Kelly, Mr. James|  male|34.5|    0|    0|          330911| 7.8292| NULL|       Q|\n",
      "|        893|       1|     3|Wilkes, Mrs. Jame...|female|47.0|    1|    0|          363272|    7.0| NULL|       S|\n",
      "|        894|       0|     2|Myles, Mr. Thomas...|  male|62.0|    0|    0|          240276| 9.6875| NULL|       Q|\n",
      "|        895|       0|     3|    Wirz, Mr. Albert|  male|27.0|    0|    0|          315154| 8.6625| NULL|       S|\n",
      "|        896|       1|     3|Hirvonen, Mrs. Al...|female|22.0|    1|    1|         3101298|12.2875| NULL|       S|\n",
      "|        897|       0|     3|Svensson, Mr. Joh...|  male|14.0|    0|    0|            7538|  9.225| NULL|       S|\n",
      "|        898|       1|     3|Connolly, Miss. Kate|female|30.0|    0|    0|          330972| 7.6292| NULL|       Q|\n",
      "|        899|       0|     2|Caldwell, Mr. Alb...|  male|26.0|    1|    1|          248738|   29.0| NULL|       S|\n",
      "|        900|       1|     3|Abrahim, Mrs. Jos...|female|18.0|    0|    0|            2657| 7.2292| NULL|       C|\n",
      "|        901|       0|     3|Davies, Mr. John ...|  male|21.0|    2|    0|       A/4 48871|  24.15| NULL|       S|\n",
      "|        902|       0|     3|    Ilieff, Mr. Ylio|  male|NULL|    0|    0|          349220| 7.8958| NULL|       S|\n",
      "|        903|       0|     1|Jones, Mr. Charle...|  male|46.0|    0|    0|             694|   26.0| NULL|       S|\n",
      "|        904|       1|     1|Snyder, Mrs. John...|female|23.0|    1|    0|           21228|82.2667|  B45|       S|\n",
      "|        905|       0|     2|Howard, Mr. Benjamin|  male|63.0|    1|    0|           24065|   26.0| NULL|       S|\n",
      "|        906|       1|     1|Chaffee, Mrs. Her...|female|47.0|    1|    0|     W.E.P. 5734| 61.175|  E31|       S|\n",
      "|        907|       1|     2|del Carlo, Mrs. S...|female|24.0|    1|    0|   SC/PARIS 2167|27.7208| NULL|       C|\n",
      "|        908|       0|     2|   Keane, Mr. Daniel|  male|35.0|    0|    0|          233734|  12.35| NULL|       Q|\n",
      "|        909|       0|     3|   Assaf, Mr. Gerios|  male|21.0|    0|    0|            2692|  7.225| NULL|       C|\n",
      "|        910|       1|     3|Ilmakangas, Miss....|female|27.0|    1|    0|STON/O2. 3101270|  7.925| NULL|       S|\n",
      "|        911|       1|     3|\"Assaf Khalil, Mr...|female|45.0|    0|    0|            2696|  7.225| NULL|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataf_drop.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+-------+---------------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|     Ticket|   Fare|          Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+-------+---------------+--------+\n",
      "|        904|       1|     1|Snyder, Mrs. John...|female|23.0|    1|    0|      21228|82.2667|            B45|       S|\n",
      "|        906|       1|     1|Chaffee, Mrs. Her...|female|47.0|    1|    0|W.E.P. 5734| 61.175|            E31|       S|\n",
      "|        916|       1|     1|Ryerson, Mrs. Art...|female|48.0|    1|    3|   PC 17608|262.375|B57 B59 B63 B66|       C|\n",
      "|        918|       1|     1|Ostby, Miss. Hele...|female|22.0|    0|    1|     113509|61.9792|            B36|       C|\n",
      "|        920|       0|     1|Brady, Mr. John B...|  male|41.0|    0|    0|     113054|   30.5|            A21|       S|\n",
      "|        926|       0|     1|Mock, Mr. Philipp...|  male|30.0|    1|    0|      13236|  57.75|            C78|       C|\n",
      "|        933|       0|     1|Franklin, Mr. Tho...|  male|NULL|    0|    0|     113778|  26.55|            D34|       S|\n",
      "|        936|       1|     1|Kimball, Mrs. Edw...|female|45.0|    1|    0|      11753|52.5542|            D19|       S|\n",
      "|        938|       0|     1|Chevre, Mr. Paul ...|  male|45.0|    0|    0|   PC 17594|   29.7|             A9|       C|\n",
      "|        940|       1|     1|Bucknell, Mrs. Wi...|female|60.0|    0|    0|      11813|76.2917|            D15|       C|\n",
      "|        942|       0|     1|Smith, Mr. Lucien...|  male|24.0|    1|    0|      13695|   60.0|            C31|       S|\n",
      "|        945|       1|     1|Fortune, Miss. Et...|female|28.0|    3|    2|      19950|  263.0|    C23 C25 C27|       S|\n",
      "|        949|       0|     3|Abelseth, Mr. Ola...|  male|25.0|    0|    0|     348122|   7.65|          F G63|       S|\n",
      "|        951|       1|     1|Chaudanson, Miss....|female|36.0|    0|    0|   PC 17608|262.375|            B61|       C|\n",
      "|        956|       0|     1|Ryerson, Master. ...|  male|13.0|    2|    2|   PC 17608|262.375|B57 B59 B63 B66|       C|\n",
      "|        960|       0|     1|Tucker, Mr. Gilbe...|  male|31.0|    0|    0|       2543|28.5375|            C53|       C|\n",
      "|        961|       1|     1|Fortune, Mrs. Mar...|female|60.0|    1|    4|      19950|  263.0|    C23 C25 C27|       S|\n",
      "|        965|       0|     1|Ovies y Rodriguez...|  male|28.5|    0|    0|   PC 17562|27.7208|            D43|       C|\n",
      "|        966|       1|     1|Geiger, Miss. Amalie|female|35.0|    0|    0|     113503|  211.5|           C130|       C|\n",
      "|        967|       0|     1|  Keeping, Mr. Edwin|  male|32.5|    0|    0|     113503|  211.5|           C132|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+-------+---------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataf_drop.na.drop(subset=['Cabin']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+----------------+\n",
      "|                Name|     min(Ticket)|     max(Ticket)|\n",
      "+--------------------+----------------+----------------+\n",
      "|\"Assaf Khalil, Mr...|            2696|            2696|\n",
      "|\"Coutts, Mrs. Wil...|      C.A. 37671|      C.A. 37671|\n",
      "|\"Johnston, Mrs. A...|      W./C. 6607|      W./C. 6607|\n",
      "|\"Katavelas, Mr. V...|            2682|            2682|\n",
      "|\"Khalil, Mrs. Bet...|            2660|            2660|\n",
      "|\"Lindeberg-Lind, ...|           17475|           17475|\n",
      "|\"Moubarek, Mrs. G...|            2661|            2661|\n",
      "|\"Nakid, Mrs. Said...|            2653|            2653|\n",
      "|\"Nourney, Mr. Alf...|   SC/PARIS 2166|   SC/PARIS 2166|\n",
      "|\"Rosenshine, Mr. ...|        PC 17585|        PC 17585|\n",
      "|\"Thomas, Mrs. Ale...|            2625|            2625|\n",
      "|\"Wells, Mrs. Arth...|           29103|           29103|\n",
      "|\"Willer, Mr. Aaro...|            3410|            3410|\n",
      "|Abbott, Master. E...|       C.A. 2673|       C.A. 2673|\n",
      "|Abelseth, Miss. K...|          348125|          348125|\n",
      "|Abelseth, Mr. Ola...|          348122|          348122|\n",
      "|Abrahamsson, Mr. ...|SOTON/O2 3101284|SOTON/O2 3101284|\n",
      "|Abrahim, Mrs. Jos...|            2657|            2657|\n",
      "|Aks, Master. Phil...|          392091|          392091|\n",
      "|Aldworth, Mr. Cha...|          248744|          248744|\n",
      "+--------------------+----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataf.groupBy('Name').agg(min('Ticket'), max('Ticket')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "print(dataf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'Ticket'>\n"
     ]
    }
   ],
   "source": [
    "print(dataf['Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|          Ticket|\n",
      "+----------------+\n",
      "|          330911|\n",
      "|          363272|\n",
      "|          240276|\n",
      "|          315154|\n",
      "|         3101298|\n",
      "|            7538|\n",
      "|          330972|\n",
      "|          248738|\n",
      "|            2657|\n",
      "|       A/4 48871|\n",
      "|          349220|\n",
      "|             694|\n",
      "|           21228|\n",
      "|           24065|\n",
      "|     W.E.P. 5734|\n",
      "|   SC/PARIS 2167|\n",
      "|          233734|\n",
      "|            2692|\n",
      "|STON/O2. 3101270|\n",
      "|            2696|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataf.select('Ticket').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Pclass|\n",
      "+------+\n",
      "|     1|\n",
      "|     3|\n",
      "|     2|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataf.select('Pclass').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   Fare|\n",
      "+-------+\n",
      "| 8.5167|\n",
      "|   15.5|\n",
      "| 29.125|\n",
      "| 7.7208|\n",
      "| 7.7333|\n",
      "|   15.9|\n",
      "|41.5792|\n",
      "|14.4542|\n",
      "|14.4583|\n",
      "|27.7208|\n",
      "|   46.9|\n",
      "| 7.8292|\n",
      "|20.2125|\n",
      "|75.2417|\n",
      "|   15.1|\n",
      "|27.4458|\n",
      "|  9.325|\n",
      "| 151.55|\n",
      "| 13.775|\n",
      "|14.1083|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataf.select('Fare').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf.select('Fare').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf.select('Fare').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf.select('Parch').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf[dataf['Fare'].isNull()].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf.na.fill('0.0', ['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf[dataf['Fare'].isNull()].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf[dataf['Fare']==0.0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = spark.read.csv('tested.csv', header=True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf.describe('Cabin').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf.select('Cabin').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = dataf.na.fill(\"No Cabin for this passenger\", [\"Cabin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf[dataf['Fare'].isNull()].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanFare = dataf.select(mean(dataf['Fare'])).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meanFare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = dataf.na.fill(meanFare, ['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf[dataf['Fare'].isNull()].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf_mysoginy = dataf.groupBy('Sex').agg(avg('Fare'),min('Fare'),max('Fare'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf_mysoginy.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_indexer = StringIndexer(inputCol='Sex', outputCol='Sex_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sex_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_encoder = OneHotEncoder(inputCol='Sex_index',outputCol='OneHotSex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sex_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[sex_indexer, sex_encoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipeline.fit(dataf).transform(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv('data transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.drop('OneHotSex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped.write.csv('New Data.csv', header = True, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
